{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "12Nov2020 - MLOps II Laboratory ",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datarobot-community/DRU-MLOps-wip/blob/master/12Nov2020_MLOps_II_Laboratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcHrfkRkwUDC"
      },
      "source": [
        "# MLOps II Laboratory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLTGmStO-gGe"
      },
      "source": [
        "**Pre-requisites:**\n",
        "1. You need a DataRobot account and API key.  \n",
        "2. Add your API Key and DataRobot URL to the first cell in the notebook. The API Key is found in the Developer Tools which is located on the profile icon in the DataRobot GUI App.\n",
        "\n",
        "\n",
        "**Documentation:**\n",
        "\n",
        "The MLOps Agent tarball includes documentation in the docs folder.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP50QKUSlf3N"
      },
      "source": [
        "# 1.- Add your API_KEY and the location of the DataRobot instance you are using.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO-YkhlNMJ0d"
      },
      "source": [
        "import yaml\n",
        "import requests\n",
        "import re\n",
        "API_KEY = \"\"\n",
        "DR_URL = \"https://app.datarobot.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH8kNamy0fQe"
      },
      "source": [
        "The following two shell commands will show you \\\n",
        "a) where we are within the Colab runtime and \\\n",
        "b) what is contained within it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKt1hmm_CXlF"
      },
      "source": [
        "% pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQYHjeTOCZrj"
      },
      "source": [
        "% ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSB9WHitSpg8"
      },
      "source": [
        "# 2.- Download the MLOps Agent tarball to the local Colab directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INs7K0_Fpjax"
      },
      "source": [
        "url = DR_URL + \"/api/v2/mlopsInstaller\"\n",
        "\n",
        "headers = {'Authorization': 'Bearer {}'.format(API_KEY)}\n",
        "response = requests.request(\"GET\", url, headers=headers)\n",
        "if 'UNAUTHORIZED' in response.reason:\n",
        "    print('Put your real API key in')\n",
        "with open(\"mlops-agents.tar.gz\", \"wb\") as f:\n",
        "    f.write(response.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCy3QeyFZ7rW"
      },
      "source": [
        "#Lets grab the filename which has the latest version\n",
        "d = response.headers['content-disposition']\n",
        "fname = re.findall(\"filename=(.+).tar.gz\", d)[0]\n",
        "n = fname.rfind(\"-\")\n",
        "filename = fname[:n]\n",
        "filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DYJydZ-Cdey"
      },
      "source": [
        "% ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UFVSkdw1qpJ"
      },
      "source": [
        "As shown by the output of the previous shell command, we now have the MLOps Agent tarball within the runtime."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk7-p5MR8dTR"
      },
      "source": [
        "# 3.- Untar the MLOPs Agent tarball, and then create a tmp directory to spool the predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVWLKh-CMQBv"
      },
      "source": [
        "!tar -xvf /content/mlops-agents.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4ZF00o-8dTW"
      },
      "source": [
        "# Here we create the directory where the spool file will be located\n",
        "%cd $filename\n",
        "!mkdir -p /tmp/ta\n",
        "%ls -al"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFDxyVAx8dTZ"
      },
      "source": [
        "# 4.-  Install the MLOps library.\n",
        "\n",
        "### The tarball contains a Wheel file that wiil be used to install the MLOps Agent Libraries:  \n",
        "### **lib/datarobot_mlops-6.2.4-py2.py3-none-any.whl** \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZmRJck88dTa"
      },
      "source": [
        "!pip install lib/datarobot_mlops-6.2.4-py2.py3-none-any.whl   ##If you have a newer version of the agent, this could be different filename"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHnHZ-bh8dTd"
      },
      "source": [
        "# 5.- Edit mlops.agent.conf.yaml\n",
        "\n",
        "This file contains the properties used in the configuration of the MLOps service.  For this notebook, you will only need to set the DR host and your API token."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQr9bvXW8dTe"
      },
      "source": [
        "with open(r'conf/mlops.agent.conf.yaml') as file:      # read the yaml file as a dictionary\n",
        "    documents = yaml.load(file)\n",
        "\n",
        "# Set your DR host:\n",
        "documents['mlopsUrl'] = DR_URL                         # set the required values in this dictionary\n",
        "# Set your API token\n",
        "documents['apiToken'] = API_KEY\n",
        "\n",
        "with open('conf/mlops.agent.conf.yaml', \"w\") as f:     # write back the dictionary to the yaml file\n",
        "    yaml.dump(documents, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tnrBpIXoP0n"
      },
      "source": [
        "In this notebook we will use FS_SPOOL as the messaging channel. More sophisticated monitoring will likely use other channels.\n",
        "\n",
        "channelConfigs:\n",
        "   - type: “FS_SPOOL”\n",
        "     details: {name: “bench”, spoolDirectoryPath: “/tmp/ta”}\n",
        "   - type: “SQS_SPOOL”\n",
        "     details: {name: “sqsSpool”, queueUrl: “https://SQS_URL”}\n",
        "   - type: “PUBSUB_SPOOL”\n",
        "     details: {name: “pubsubSpool”, projectId: “yourprojectId”, topicName: “yourtopicName”}\n",
        "   - type: “RABBITMQ_SPOOL”\n",
        "     details: {name: “rabbit”, queueName: “rabbitmq”, queueUrl: “https://SQS_URL”}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HJ4TMHkIl9a"
      },
      "source": [
        "Verify the changes in the mlops.agent.conf.yaml.  You should see the correct MLOps URL and API token.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaII-yRZ8dTg"
      },
      "source": [
        "print(open('conf/mlops.agent.conf.yaml').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-z9kqii8dTp"
      },
      "source": [
        "# 6.- Start the agent and get its status\n",
        "\n",
        "The following shell commands are required to \\\n",
        "a) start the MLOps Agent service. \\\n",
        "b) get the status of the MLOps Agent service. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFfZ0Wsg8dTq"
      },
      "source": [
        "# Start the agent\n",
        "!./bin/___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3m8RqUBV8dTt"
      },
      "source": [
        "# Get agent status\n",
        "!./bin/___"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2hQkAYG8dT0"
      },
      "source": [
        "# 7.- Load sample data and split it into training and testing sets \n",
        "\n",
        "* The training data is the exact same one used to train the model pipeline that will be used in this laboratory \\\n",
        "* The test data will play the role of the scoring data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqI3KAE38dT1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import csv\n",
        "import pytz\n",
        "import json\n",
        "import yaml\n",
        "import datetime\n",
        "import joblib\n",
        "\n",
        "TRAINING_DATA = './examples/data/surgical-dataset.csv'\n",
        "\n",
        "df = pd.read_csv(TRAINING_DATA)\n",
        "\n",
        "columns = list(df.columns)\n",
        "arr = df.to_numpy()\n",
        "\n",
        "np.random.shuffle(arr)\n",
        "\n",
        "split_ratio = 0.8\n",
        "prediction_threshold = 0.5\n",
        "\n",
        "train_data_len = int(arr.shape[0] * split_ratio)\n",
        "\n",
        "train_data = arr[:train_data_len, :-1]\n",
        "label = arr[:train_data_len, -1]\n",
        "test_data = arr[train_data_len:, :-1]\n",
        "test_df = df[train_data_len:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n73VMdJBI8-t"
      },
      "source": [
        "# 8.- Create and deploy an external model package\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooOxNPA0pWhR"
      },
      "source": [
        "First we will inspect the JSON file that contains the model configuration for this example. This is necessary as we will create an external model package via code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JwkNds2perS"
      },
      "source": [
        "print(open('./examples/model_config/surgical_binary_classification.json').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO2REaYqpocY"
      },
      "source": [
        "The name specified in this JSON file is the name that the external model package will have in the  MLOps GUI\n",
        "\n",
        "We will now \\\n",
        "a) create & deploy the external model package. \\\n",
        "b) upload training data to MLOPs in order to monitor data drift."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2HijJmj8dT8"
      },
      "source": [
        "# Here we set the name of the deployment that will be seen in the MLOps GUI\n",
        "DEPLOYMENT_NAME=\"Google Collab MLOps II Lab - Python binary classification\"\n",
        "\n",
        "# MLOps Agent Library imports\n",
        "from datarobot.mlops.mlops import MLOps\n",
        "from datarobot.mlops.common.enums import OutputType\n",
        "from datarobot.mlops.connected.client import MLOpsClient\n",
        "from datarobot.mlops.common.exception import DRConnectedException\n",
        "from datarobot.mlops.constants import Constants\n",
        "\n",
        "# Read the model configuration info from the JSON file. This is used to create the remote model package.\n",
        "with open('./examples/model_config/surgical_binary_classification.json', \"r\") as f:\n",
        "    model_info = json.loads(f.read())\n",
        "model_info\n",
        "\n",
        "# Read the MLOps connection info from the YAML file\n",
        "with open('conf/mlops.agent.conf.yaml') as file:\n",
        "    # The FullLoader parameter handles the conversion from YAML\n",
        "    # scalar values to Python dictionary format\n",
        "    agent_yaml_dict = yaml.load(file, Loader=yaml.Loader) ##CHANGE##\n",
        "\n",
        "# Here are the values of the API key and the MLOps URL\n",
        "MLOPS_URL = agent_yaml_dict['mlopsUrl']\n",
        "API_TOKEN = agent_yaml_dict['apiToken']\n",
        "\n",
        "# Create connected client object\n",
        "mlops_connected_client = ___(___,___)\n",
        "\n",
        "# Upload training data to MLOps\n",
        "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
        "dataset_id = mlops_connected_client.___(___)    # \n",
        "\n",
        "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
        "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
        "\n",
        "# Create the model package\n",
        "print('Create model package')\n",
        "model_pkg_id = mlops_connected_client.___(___)\n",
        "\n",
        "# Get model package info \n",
        "model_pkg = mlops_connected_client.___(___)\n",
        "\n",
        "# get model id from model package info\n",
        "model_id = model_pkg[\"modelId\"]\n",
        "\n",
        "# Deploy the model package & get deployment id\n",
        "print('Deploy model package')\n",
        "deployment_id = mlops_connected_client.___(___,___)\n",
        "\n",
        "# Enable data drift tracking\n",
        "print('Enable feature drift monitoring')\n",
        "enable_feature_drift = TRAINING_DATA is not None\n",
        "mlops_connected_client.___(___,___,___)\n",
        "\n",
        "# Get deployment settings\n",
        "_ = mlops_connected_client.___(___)\n",
        "\n",
        "print(\"\\nDone.\")\n",
        "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
        "\n",
        "DEPLOYMENT_ID = deployment_id\n",
        "MODEL_ID = model_id"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmeZP5emw_SF"
      },
      "source": [
        "# 9.- Upload a pickle file with a pre-trained model pipeline to Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phQ1SHC3x23o"
      },
      "source": [
        "We will load a pickle file named \"pipeline.pkl\" (found in the zip file that contains the class material). Navigate to the folder where the class material is and select \"pipeline.pkl\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMwqJ21pSivy"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICed3RBQ8dT_"
      },
      "source": [
        "# 10.- Run Model Predictions\n",
        "\n",
        "We call the remote model's predict function and send prediction data to MLOps. Note that the model is supplied using the pickle file uploaded in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxGAVcyO8dT_"
      },
      "source": [
        "#\n",
        "# Code samples can be found in:\n",
        "# 1. under the Integration tab for your depoyment in DataRobot MLOps, or in\n",
        "# 2. the agent example code on your filesystem in ./examples/python/ and ./tools/\n",
        "#    This example is from BinaryClassificationExample\n",
        "#\n",
        "\n",
        "CLASS_NAMES = ['0', \"1\"]\n",
        "OUTPUT_TYPE = OutputType.OUTPUT_DIR\n",
        "\n",
        "# Spool directory path must match the Monitoring Agent path configured by admin in the YAML configuration file.\n",
        "SPOOL_DIR = \"/tmp/ta\"\n",
        "SPOOL_MAX_FILE_SIZE = 104857600\n",
        "SPOOL_MAX_FILES = 5\n",
        "\n",
        "# name of the file that contains actuals\n",
        "ACTUALS_OUTPUT_FILE = \"actuals.csv\"\n",
        "            \n",
        "def process_predictions(deployment_id, model_id, output_type, spool_dir, spool_max_file_size, spool_max_files, class_names):\n",
        "    \"\"\"\n",
        "    This is a binary classification algorithm example.\n",
        "    User can call the DataRobot MLOps library functions to report statistics.\n",
        "    \"\"\"\n",
        "    # load pickle file with model pipeline\n",
        "    _model = joblib.load(filename=\"pipeline.pkl\")\n",
        "\n",
        "    # Get predictions\n",
        "    start_time = time.time()\n",
        "    predictions = _model.predict_proba(test_data).tolist()\n",
        "    num_predictions = len(predictions)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    # Generate assocation ids for the predictions so we can match them with actuals\n",
        "    # this is necessary for accuracy monitoring\n",
        "    def _generate_unique_association_ids(num_samples):\n",
        "        ts = time.time()\n",
        "        return [\"x_{}_{}\".format(ts, i) for i in range(num_samples)]\n",
        "    association_ids = _generate_unique_association_ids(len(test_data))\n",
        "\n",
        "    # MLOPS: initialize the MLOps instance\n",
        "    # These are thre stpes that we need in order to initializa a MLOps Agent instance\n",
        "    # The necessary parameters are:\n",
        "    #    * deployment ID\n",
        "    #    * model id\n",
        "    #    * output type\n",
        "    #    * spool directory\n",
        "    #    * maximum spool file size\n",
        "    #    * maximum number of spool files\n",
        "    print(\"Get an MLOps instance\")\n",
        "    mlops = MLOps().___(___)\\\n",
        "                   .___(___)\\\n",
        "                   .___(___)\\\n",
        "                   .___(___)\\\n",
        "                   .___(___)\\\n",
        "                   .___(___)\\\n",
        "                   .___()\n",
        "\n",
        "    # MLOPS: report the number of predictions in the request and the execution time.\n",
        "    print(\"Send MLOps deployment stats\")\n",
        "    mlops.___(___,___)\n",
        "\n",
        "    # MLOPS: report the predictions data: features, predictions, class_names\n",
        "    print(\"Send MLOps prediction data\")\n",
        "    mlops.___(___,____,____,____)\n",
        "    \n",
        "    target_column_name = columns[len(columns) - 1]\n",
        "    target_values = []\n",
        "    orig_labels = test_df[target_column_name].tolist()\n",
        "    \n",
        "    print(\"Wrote actuals file: %s\" % ACTUALS_OUTPUT_FILE)\n",
        "    def write_actuals_file(out_filename, test_data_labels, association_ids):\n",
        "        \"\"\"\n",
        "         Generate a CSV file with the association ids and labels, this example\n",
        "         uses a dataset that has labels already.\n",
        "         In a real use case actuals (labels) will show after prediction is done.\n",
        "\n",
        "        :param out_filename:      name of csv file\n",
        "        :param test_data_labels:  actual values (labels)\n",
        "        :param association_ids:   association id list used for predictions\n",
        "        \"\"\"\n",
        "        with open(out_filename, mode=\"w\") as actuals_csv_file:\n",
        "            writer = csv.writer(actuals_csv_file, delimiter=\",\")\n",
        "            writer.writerow(\n",
        "                [\n",
        "                    Constants.ACTUALS_ASSOCIATION_ID_KEY,\n",
        "                    Constants.ACTUALS_VALUE_KEY,\n",
        "                    Constants.ACTUALS_TIMESTAMP_KEY\n",
        "                ]\n",
        "            )\n",
        "            tz = pytz.timezone(\"America/Los_Angeles\")\n",
        "            for (association_id, label) in zip(association_ids, test_data_labels):\n",
        "                actual_timestamp = datetime.datetime.now().replace(tzinfo=tz).isoformat()\n",
        "                writer.writerow([association_id, \"1\" if label else \"0\", actual_timestamp])\n",
        "\n",
        "        \n",
        "    # Write csv file with labels and association Id, when output file is provided\n",
        "    write_actuals_file(ACTUALS_OUTPUT_FILE, orig_labels, association_ids)\n",
        "\n",
        "    # MLOPS: release MLOps resources when finished.\n",
        "    mlops.___()\n",
        "\n",
        "    print(\"Done4.\")\n",
        "\n",
        "process_predictions(DEPLOYMENT_ID, MODEL_ID, OUTPUT_TYPE, SPOOL_DIR, SPOOL_MAX_FILE_SIZE, SPOOL_MAX_FILES, CLASS_NAMES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak-Oh7EN8dUC"
      },
      "source": [
        "# 11.- Upload actuals back to MLOps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjnMjSnZ8dUC"
      },
      "source": [
        "def _get_correct_actual_value(deployment_type, value):\n",
        "    if deployment_type == \"Regression\":\n",
        "        return float(value)\n",
        "    return str(value)\n",
        "\n",
        "def _get_correct_flag_value(value_str):\n",
        "    if value_str == \"True\":\n",
        "        return True\n",
        "    return False\n",
        "    \n",
        "def upload_actuals():\n",
        "    print(\"Connect MLOps client\")           # create connected client object\n",
        "    mlops_connected_client = ___(___,___)\n",
        "\n",
        "    # get deployment type\n",
        "    deployment_type = mlops_connected_client.___(___)\n",
        "\n",
        "    # read actuals file\n",
        "    actuals = []\n",
        "    with open(ACTUALS_OUTPUT_FILE, mode=\"r\") as actuals_csv_file:\n",
        "        reader = csv.DictReader(actuals_csv_file)\n",
        "        for row in reader:\n",
        "            actual = {}\n",
        "            for key, value in row.items():\n",
        "                if key == Constants.ACTUALS_WAS_ACTED_ON_KEY:\n",
        "                    value = _get_correct_flag_value(value)\n",
        "                if key == Constants.ACTUALS_VALUE_KEY:\n",
        "                    value = _get_correct_actual_value(deployment_type, value)\n",
        "                actual[key] = value\n",
        "            actuals.append(actual)\n",
        "\n",
        "            # actuals are submitted if there are 10000 of them\n",
        "            if len(actuals) == 10000:\n",
        "                mlops_connected_client.___(___,___)\n",
        "                actuals = []\n",
        "\n",
        "    # Upload actuals to MLOps\n",
        "    print(\"Submit actuals\")\n",
        "    mlops_connected_client.___(___, ___)\n",
        "    \n",
        "    print(\"Done.\")    \n",
        "\n",
        "upload_actuals()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3GLIykY8dUF"
      },
      "source": [
        "# 12.- Stop the mlops service"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRTyi3Tr8dUF"
      },
      "source": [
        "!bin/stop-agent.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAAScaS0FbtQ"
      },
      "source": [
        "# 13.- Inspect the MLOps agent logs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EyA854mr8dUI"
      },
      "source": [
        "cat /content/datarobot-mlops-agent-6.2.4/logs/mlops.agent.log"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}